---
title: 'Replication of Inferring Identity From Language: Linguistic Intergroup Bias Informs Social Categorization by Shanette C. Porter, Michelle Rheinschmidt-Same, and Jennifer A. Richeson (2016, Psychological Science)'
author: "Lindsey Hasak (lrhasak@stanford.edu)"
date: "December 14, 2018"
output:
  html_document:
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
  pdf_document:
    toc: yes
    toc_depth: '3'
---
[Github Repository](https://github.com/lrhasak/porter2016)

[Link to Qualtrics Survey](https://stanforduniversity.qualtrics.com/jfe/form/SV_8uHPBQ44Dl5Q5Zb)

[Link to Preregistration](https://osf.io/r73d8/)

```{r}
suppressMessages(require(pwr))
```

##Introduction
 
  Porter, Rheinschmidt-Same, and Richeson (2016) aimed to test how linguistic intergroup bias (LIB) affects individuals' inferences about communicator's social identities. In Study 1a, participants were asked about a communicator's political preference in favorable and unfavorable LIB conditions. Study 1b examined the generalizability of the effect found in 1a by asking participants about the communicator's religion. In Study 2, Porter et al. tested LIB more subtly by asking participants to discern the communicator's preferences about social policies Finally, in Study 3, Porter et al. investigated other possible influences for the results of the study by controlling for between-conditions differences and group membership of the target. 
  I aim to replicate the results of Study 2 by posing the same questions about social-policy preferences to participants through Amazon Mechanical turk. If replicated, I expect the data to show that participants in the favorable-LIB condition believed that the communicator supported typically Democratic social policies and was a Democrat, as compared the participants in the unfavorable-LIB condition. Additionally, these results should not be modulated by the participants' self-reported political party and ideology.


##Methods

###Power Analysis

Porter et al. estimated that 120 participants would be sufficient for Study 2, given the effect sizes of *d* = 0.53, *d* = 0.80,and *d* = 0.62 in Study 1a. They ultimately collected data from 118 participants. The original effect size for Study 2 was *d* = 0.60 with 118 participants. A power analysis reveals that I would need 42 participants in each condition for 80% power, 60 participants in each condition for 90% power, and 74 participants in each group for 95% power. Given the financial constraints of each class, I will plan to test 84 participants for a replication at 80% power.

```{r}
pwr.t.test(n  = NULL, d = .62, sig.level = .05, power = .80, type = c("two.sample"))
```
```{r}
pwr.t.test(n  = NULL, d = .60, sig.level = .05, power = .90, type = c("two.sample"))
```
```{r}
pwr.t.test(n  = NULL, d = .60, sig.level = .05, power = .95, type = c("two.sample"))
```


###Planned Sample

The planned sample size is 84 participants, after which data collection will end. While the aim is to have self-reported political party affiliations reflect the original study (30.5% Democrat, 31.4% Republican, 33.1% Independent, 2.5% "other", and 2.5% not reported), participants will not be screened for party affiliation before being allowed to participate.

###Materials

Communicator Statement - All participants
"Imagine that someone is communicating with you about a man named Peter. Peter is American, has an interest in politics, and voted for Barack Obama."

Communicator Statement - Favorable LIB Condition (followed precisely from Porter et al., 2016)
"The communicator states the following about Peter: Peter has helped many people, even when it did not benefit him. IN my view, he is someone who stands up for the interests of others. I think he is socially very responsible. On the other hand, Peter said something rude to another person recently. In my opinion, he acted cold and did something unfriendly."

Communicator Statement - Unfavorable LIB Condition (followed precisely from Porter et al., 2016)
"The communicator states the following about Peter: Peter helped another person, even when it did not benefit him. In my view, he is someone who acted in the interests of that person, as well as stood up for the interests of that person. On the other hand, Peter is rude to many people. In my opinion, he is cold and unfriendly."

Explicit Social Categorization of the Communicator (followed precisely from Porter et al., 2016)

"How do you think the COMMUNICATOR would feel about eliminating race-based Affirmative Action?"

"How do you think the COMMUNICATOR would feel about increasing the level of legal immigration?"

"How do you think the COMMUNICATOR would feel about increasing taxes on the wealthy?"

"How do you think the COMMUNICATOR would feel about legalizing same-sex marriage?"

Scale for Answering questions about communicator statements (followed precisely from Porter et al., 2016)
"1 = Strongly opposed
2 = Moderately opposed
3 = Slightly opposed
4 = Neutral
5 = Slightly in favor
6 = Moderately in favor
7 = Strongly in favor"

Demographic Questions and Potential Answers (followed precisely from Porter et al., 2016)

"What is your marital status?
Answer choices: Single, married

What is your gender?
Answer choices: male, female

Are you a US citizen?
Answer choices: yes, no

How many children live in your household?
Answer choices: 0-10

Approx. how may surveys have you completed in the last 30 days?
Answer choices: 0-1000

How warmly do you feel toward Democrats, in general?
Answer choices: 0-100

What is your race/ethnicity?
Asnwer choices: White, Black, Asian, Latino, Native American, Other

What is your age?
Asnwer choices: 0-100
I endorse many aspects of conservative political ideology
Answer choices:
1 - Strongly disagree
2 - Disagree
3 - Somewhat disagree
4 - Neither agree nor disagree
5 - Somewhat agree
6 - Agree
7 - Strongly agree

I endorse many aspects of liberal political ideology
Answer choices:
1 - Strongly disagree
2 - Disagree
3 - Somewhat disagree
4 - Neither agree nor disagree
5 - Somewhat agree
6 - Agree
7 - Strongly agree

In general, how would you describe your political views on social issues?
Asnwer choices:
1 - Very liberal
2 - Somewhat liberal
3 - Middle of the road
4 - Somewhat conservative
5 - Very conservative

Generally speaking, do you usually consider yourself a Democrat, a Republican, an Independent, or affliliated with another political party?
Answer choices:
1 - Democrat
2 - Republican
3 - Independent
4 - Other Political Party
If other: Text Response

Note if you have completed a survey like this before and if anything seemed strange
Answer: Text Response"

###Procedure	

Followed precisely from Study 2 of Porter et al. (2016): 
"Participants read one of the short passages from Study 1a and then responded to a series of questions measuring their beliefs about the communicator's attitudes regarding social-policy issues in the United States for which the political parties have well-known stances. The specific issues were (a) increasing legal immigration to the United States, (b) increasing taxes on the wealthy, and (c) legalizing same-sex marriage." Participants responded on 7-point scales, ranging from 1, ***strongly opposed*** to 7, ***strongly in favor***. Participants then completed the explicit social categorization of the communicator, as described in Study 1a, and the same demographic questionnaire used in Study 1a."

###Analysis Plan

For study 2, Porter et al. reported that "The ratings for the social-policy issues were averaged to form a composite (alpha = .63)^{1}." This replication will also form a composite score for social-policy issues. The notation about the composite explains that "in a factor analysis, a fourth policy, eliminating affirmative action, did not load with the other items, but revealed the same pattern: Participants in the favorable-LIB condition believed that the communicator was less likely to support the policy (*M* = 3.83, *SD*  = 1.44) than did participants in the unfavorable-LIB condition (*M* = 4.45, *SD* = 1.13), *t*(116) = 2.61, *p* = .01." To keep the analysis strategy as close to the original as possible, I will also eliminate the affirmative action data from the composite, but report if it followed the trend on its own. 
My main analysis is an independent-samples t-test to see if my data replicates the finding that "participants in the favorable-LIB condition believed that the communicator was more likely to support these Democratic-leaning social policies (*M* = 4.90, *SD* = 0.99), compared with participants in the unfavorable-LIB condition (*M* = 4.33, *SD* = 0.90), *t*(116) = 3.25, *p* = .002, *d* = 0.60.


###Differences from Original Study

Both the original sample and the replication will be conducted through MTurk. The original study had 63 participants in the unfavorable LIB condition, and 55 in the favorable LIB condition; this replication will try to have an equal amount of participants in both conditions. The authors did not report which test they used to determine if "self-reported political-party affiliation [or] their political-ideology endorsements moderated this result," so I am assuming that they conducted further independent-samples t-tests by party affiliation. Additionally, Porter et al. excluded 2 participants from their sample who "did not complete the dependent measures"; unless a similar occurrence happens, I will include all participant data in my analyses, which I do not anticipate making a difference in the results.


### Methods Addendum (Post Data Collection)

#### Actual Sample
84 participants (58 men, 26 women; mean age = 36.14 years, *SD* = 10.05 years) were recruited from Amazon Mechanical Turk (MTurk.com). 6 participants were excluded for participating from a location outside of the US, despite a location criterion set on MTurk. The remaining participants were 73% White, 10% Asian, 8% Black or African American, 2.5% Latino, 2.5% American Indian or Alaska Native, and 4% Other. 
Participants reported a range from 0-100 when asked "How warmly do you feel toward Democrats in general (0 Least Warm to 100 Most Warm)," with a mean rating of 61.20 (*SD* = 29.19).Self-reported party affiilations were as follows: 44% Democrat, 24% Republican, 22% Independent, 1% "other", and 9% not reported. This is a less equal distribution of political parties than Porter et al.'s study 2 distribution, which had roughly 30-33% of participants in each of the major political parties. The final sample also ended up with a slightly skewed distribution of participants in each condition: 36 participants were in the Favorable-LIB condition, and 42 were in the Unfavorable. This difference is exacerbated by the fact that 5 out of 6 participants who were excluded due to invalid location were in the Favorable-LIB condition.

#### Demographics
```{r}
####Load Relevant Libraries and Functions
suppressMessages(library(tidyverse))
suppressMessages(library(dplyr))
suppressMessages(library(car))
suppressMessages(library(tidyr))
suppressMessages(library(data.table))
library(RColorBrewer)

####Import data
final.data <- read.csv("/Users/lindseyhasak/Desktop/PorterData_Scrubbed.csv", header = TRUE) #Import downloaded data from Qualtrix

#### Data exclusion / filtering
filtered.final <- final.data %>% #Get rid of columns that won't matter for any data analysis
  select(-Start.Date,
         -End.Date,
         -Response.Type,
         -Progress,
         -Duration..in.seconds.,
         -Finished,
         -Recorded.Date,
         -Distribution.Channel,
         -User.Language)

#Compute mean and SD age for demographics section

age <- as.numeric(as.character(filtered.final$What.is.your.age.)) #Two rows had characters entered instead of actual age, which caused the column to be read as a factor. 
mean(age, na.rm = TRUE)
sd(age, na.rm = TRUE)
```

```{r}
#Compute race characteristics - % in demographic section is this number divided by 78 (total number of participants) and rounded up to the nearest percent.
race <- as.factor(filtered.final$What.is.your.race.ethnity....Selected.Choice)
summary(race)
```

```{r}
#Compute feeling of warmth towards democrats
dem.warmth <- as.numeric(as.character(filtered.final$How.warmly.do.you.feel.toward.Democrats..in.general...0..Least.Warm...100..Most.Warm.))
mean(dem.warmth, na.rm = TRUE)
sd(dem.warmth, na.rm = TRUE)
range(dem.warmth, na.rm = TRUE) #Wanted to see because of the very large SD
```

```{r}
#Compute explicit political party
politics <- as.factor(filtered.final$Generally.speaking..do.you.usually.consider.yourself.a.Democrat..a.Republican..an.Independent..or.affiliated.with.another.political.party.)
summary(politics)
#"A disappointed in my party Democrat" will be coded as Democrat; "political party", "good", "none", "yes", and "None" will be coded as Not Reported" - % in demographic section are these numbers totaled and divided by 78, and rounded up to the nearest percent.

library(forcats)

#Recode reported political parties into levels
politics_recode <- fct_recode(politics, 
                              Democrat = "democrat", 
                              Democrat = "Democrat ", 
                              Democrat = "Dem",
                              Democrat = "Democrat", 
                              Democrat = "a disappointed in my party Democrat",
                              Republican = " Republican", 
                              Republican = "a Republican", 
                              Republican = "A Repulican", 
                              Republican = "republican", 
                              Republican = "A republican", 
                              Republican = "R", 
                              Republican = "Republican",
                              Independent = "Independent", 
                              Independent = "Independent ", 
                              Independent = "independent", 
                              Independent = "independent ",
                              Not.Reported = "Good", 
                              Not.Reported = "none", 
                              Not.Reported = "yes", 
                              Not.Reported = "no", 
                              Not.Reported = "None", 
                              Not.Reported = "political party",
                              Other = "Democratic Socialist")
summary(politics_recode)

```

#### Differences from pre-data collection methods plan
As explained above, the conditions ended up with slightly unequal group sizes due to exclusion criteria. Additionally, an attention check was added to determine if participants had read the communicator statements. Participants were asked "What was the name of the man that the COMMUNICATOR described?," and the correct answer was "Peter". 13/84 participants did not answer correctly. Some answers (n = 5) were reasonable (i.e., "communicator"; "Barack Obama"), and the other 8 either did not remember or suggested names not in any way affiliated with the survey. All 13 participants will be excluded in an exploratory analysis below. 

##Results


### Data preparation

Data preparation following the analysis plan.
	
```{r}
###Data Preparation - is this supposed to be commented out in the final report?

#### Prepare data for analysis - create columns etc.
#Rename columns with long names to be shorter

clean.final <- rename(filtered.final, Affirmative.Action =  "How.do.you.think.the.COMMUNICATOR.would.feel.about.eliminating.race.based.Affirmative.Action.",
                                        Legal.Immigration = "How.do.you.think.the.COMMUNICATOR.would.feel.about.increasing.the.level.of.legal.immigration.",
                                        Increase.Taxes = "How.do.you.think.the.COMMUNICATOR.would.feel.about.increasing.taxes.on.the.wealthy.",
                                        Marriage.Equality = "How.do.you.think.the.COMMUNICATOR.would.feel.about.legalizing.same.sex.marriage.",
                                        Communicator.Party = "What.is.the.likelihood.that.the.COMMUNICATOR.is.either.a.Democrat.or.a.Republican.",
                                        Children.In.Household = "How.many.children.live.in.your.household...0.10.",
                                        Surveys.Completed = "Approximately.how.many.surveys.have.you.completed.in.the.last.30.days...0.1000.",
                                        Democratic.Warmth = "How.warmly.do.you.feel.toward.Democrats..in.general...0..Least.Warm...100..Most.Warm.",
                                        Conservative.Ideology = "I.endorse.many.aspects.of.conservative.political.ideology.",
                                        Liberal.Ideology = "I.endorse.many.aspects.of.liberal.political.ideology.",
                                        Social.Issues = "In.general..how.would.you.describe.your.political.views.on.social.issues.",
                                        Personal.Affiliation = "Generally.speaking..do.you.usually.consider.yourself.a.Democrat..a.Republican..an.Independent..or.affiliated.with.another.political.party.",
                                        Previous.Surveys = "Note.if.you.have.completed.a.survey.like.this.before.and.if.anything.seemed.strange.",
                                        LIB.Condition = "LIB.Condition...Display.Order"
                                        )

#Separate columns by dashes for easier analysis

analysis.final <- as.data.frame(clean.final) %>% 
  separate(col = Affirmative.Action,
           into = c("AA.Rating", "AA.Text"),
           sep = "-") %>% 
  separate(col = Legal.Immigration,
           into = c("LI.Rating", "LI.Text"),
           sep = "-") %>% 
  separate(col= Increase.Taxes,
           into = c("IT.Rating", "IT.Text"),
           sep = "-") %>% 
  separate(col = Marriage.Equality,
           into = c("ME.Rating", "ME.Text"),
           sep = "-") %>% 
  separate(col = Communicator.Party,
           into = c("CP.Rating", "CP.Text"), #creates warning about missing pieces because only ratings 1 and 7 had text associated iwth them
           sep = "-")

#Make "Rating" columns numeric

analysis.final$AA.Rating <- as.numeric(analysis.final$AA.Rating)
analysis.final$LI.Rating <- as.numeric(analysis.final$LI.Rating)
analysis.final$IT.Rating <- as.numeric(analysis.final$IT.Rating)
analysis.final$ME.Rating <- as.numeric(analysis.final$ME.Rating)
analysis.final$CP.Rating <- as.numeric(analysis.final$CP.Rating)


#Recode LIB condition into obvious variables based on presentation during Qualtrix Survey
recodeLIB <- c('Q3' = 'Favorable',
               'Q4' = 'Unfavorable')

analysis.final$LIB.Condition <- recodeLIB[clean.final$LIB.Condition]

#Add composite column of mean from immigration policy, tax policy, and same-sex marriage policy. Porter et al. did not include the affirmative action policy in the original composite.

analysis.final$Policy.Composite <- apply(analysis.final[, c("LI.Rating",
                                                      "IT.Rating", 
                                                      "ME.Rating")],1,mean)

```

### Confirmatory analysis

The analyses as specified in the analysis plan. Participants' policy ratings **replicated** the primary result from Study 2 of Porter et al. (2016). Participants in the Favorable-LIB condition were signficantly more likely to believe that the communicator would support Democratic leaning social policies (*M* = 5.45, *SD* = 0.89) than participants in the unfavorable-LIB conditon (*M* = 4.83, *SD* = 1.28), *t*(73) = 2.52, *p* = .014, *d* = 0.56 (Figure 1).

```{r}
#Compute summary statistics for confirmatory analysis
group_by(analysis.final, LIB.Condition) %>% 
  summarise(
    count = n(),
    mean = mean(Policy.Composite, na.rm = TRUE),
    sd = sd(Policy.Composite, na.rm = TRUE)
  )
```

```{r}
#Two sample t-test of policy composite by LIB condition
Policy.Rating = t.test(Policy.Composite ~ LIB.Condition, data = analysis.final)

Policy.Rating

#Since the effect was signficant, I will compute the effect size to compare to the original study.
library(effsize)
cohen.d(analysis.final$Policy.Composite, analysis.final$LIB.Condition)
```

Below is the code for producing Figure 1, a graph of the confirmatory analysis and an exploratory analysis (Communicator Party Ratings) that replicates Figure 2 from Porter et al. (2016).
```{r}
library(forcats) #Functions to find values for error bars
sem <- function(x) {sd(x, na.rm=TRUE) / sqrt(sum(!is.na((x))))}
ci <- function(x) {sem(x) * 1.96}

#Create easier df to work with for replication graph
policy.graph <- analysis.final %>% 
  select(Policy.Composite, CP.Rating, LIB.Condition) %>% #select relevant columns for analysis from analysis.final df
  group_by(LIB.Condition) %>% 
  summarize(Avg.PolComposite = mean(Policy.Composite),
            Avg.CP = mean(CP.Rating),
            Pol.CI = ci(Policy.Composite),
            CP.CI = ci(CP.Rating))  #Create avg measures of target values (Policy Composite and Communicator Party), and find values for CIs for error bars

policy.graph

#Because I had difficulty adding error bars (due to graphing 2 different datasets at once), I created another data frame in the proper format for graphing. I then added the CI column with the proper values computed in the first policy.graph df.

policy.graph2 <- policy.graph %>% 
  gather(Measure, Rating, Avg.PolComposite:Avg.CP) %>%  #tidy the data into long form: create new key column called measure and value column called Rating so that there is one observation per row for communicator ratings from each measurement per LIB condition
  group_by(LIB.Condition, Measure, Rating) %>% 
  summarise(CI = ci(Rating))

policy.graph2

#Add values to CI column for error bars
policy.graph2$CI <- as.numeric(c(.290, .386, .495, .483))

policy.graph2

#Set values to variables that can be called in geom_errorbar
upper <- policy.graph2$Rating + policy.graph2$CI
lower <- policy.graph2$Rating - policy.graph2$CI


#Replication Plot
portergraph <- ggplot(policy.graph2, aes(x = fct_rev(fct_infreq(Measure)), y = Rating, fill = LIB.Condition)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = .05, size = .25, 
                position = position_dodge(.9)) +
  labs(y = "Likelihood that the Communicator is Democratic",
       x = "Communicator Ratings",
       fill = "LIB Condition") +
  scale_x_discrete(labels = c("Avg.CP" = "Social Categorization",
                              "Avg.PolComposite" = "Policy Composite")) +
  scale_y_continuous(breaks = seq(0, 7, 0.5),
                     limits = c(0, 7)) +
  scale_fill_brewer(palette = "Paired") +
  theme_classic()

portergraph
```

![Original graph from Porter et al. (2016) for comparison.](/Users/lindseyhasak/Desktop/Porter2016Graph.jpg)

###Exploratory analyses

Before running the primary exploratory analysis, which is the t-test for the Affirmative Action trend, I wanted to re-run the primary analysis excluding the 13 participants who failed the attention check. 11 out of those 13 were in the Unfavorable-LIB condition, making the group totals 34 in the Favorable-LIB conditon, and 31 in the Unfavorable-LIB Condition.


The same analysis pipeline was run on the smaller set of participants who all passed the attention check.
```{r}
excluded.data <- read.csv("/Users/lindseyhasak/Desktop/Porter_ExcludedScrubbed.csv", header = TRUE) #Import downloaded data from Qualtrix

#### Data exclusion / filtering
filtered.excluded <- excluded.data %>% #Get rid of columns that won't matter for any data analysis
  select(-Start.Date,
         -End.Date,
         -Response.Type,
         -Progress,
         -Duration..in.seconds.,
         -Finished,
         -Recorded.Date,
         -Distribution.Channel,
         -User.Language)

#### Prepare data for analysis - create columns etc.
#Rename columns with long names to be shorter

clean.excluded <- rename(filtered.excluded, Affirmative.Action =  "How.do.you.think.the.COMMUNICATOR.would.feel.about.eliminating.race.based.Affirmative.Action.",
                                        Legal.Immigration = "How.do.you.think.the.COMMUNICATOR.would.feel.about.increasing.the.level.of.legal.immigration.",
                                        Increase.Taxes = "How.do.you.think.the.COMMUNICATOR.would.feel.about.increasing.taxes.on.the.wealthy.",
                                        Marriage.Equality = "How.do.you.think.the.COMMUNICATOR.would.feel.about.legalizing.same.sex.marriage.",
                                        Communicator.Party = "What.is.the.likelihood.that.the.COMMUNICATOR.is.either.a.Democrat.or.a.Republican.",
                                        Children.In.Household = "How.many.children.live.in.your.household...0.10.",
                                        Surveys.Completed = "Approximately.how.many.surveys.have.you.completed.in.the.last.30.days...0.1000.",
                                        Democratic.Warmth = "How.warmly.do.you.feel.toward.Democrats..in.general...0..Least.Warm...100..Most.Warm.",
                                        Conservative.Ideology = "I.endorse.many.aspects.of.conservative.political.ideology.",
                                        Liberal.Ideology = "I.endorse.many.aspects.of.liberal.political.ideology.",
                                        Social.Issues = "In.general..how.would.you.describe.your.political.views.on.social.issues.",
                                        Personal.Affiliation = "Generally.speaking..do.you.usually.consider.yourself.a.Democrat..a.Republican..an.Independent..or.affiliated.with.another.political.party.",
                                        Previous.Surveys = "Note.if.you.have.completed.a.survey.like.this.before.and.if.anything.seemed.strange.",
                                        LIB.Condition = "LIB.Condition...Display.Order"
                                        )

#Separate columns by dashes for easier analysis

analysis.excluded <- as.data.frame(clean.excluded) %>% 
  separate(col = Affirmative.Action,
           into = c("AA.Rating", "AA.Text"),
           sep = "-") %>% 
  separate(col = Legal.Immigration,
           into = c("LI.Rating", "LI.Text"),
           sep = "-") %>% 
  separate(col= Increase.Taxes,
           into = c("IT.Rating", "IT.Text"),
           sep = "-") %>% 
  separate(col = Marriage.Equality,
           into = c("ME.Rating", "ME.Text"),
           sep = "-") %>% 
  separate(col = Communicator.Party,
           into = c("CP.Rating", "CP.Text"),
           sep = "-")

#Make "Rating" columns numeric

analysis.excluded$AA.Rating <- as.numeric(analysis.excluded$AA.Rating)
analysis.excluded$LI.Rating <- as.numeric(analysis.excluded$LI.Rating)
analysis.excluded$IT.Rating <- as.numeric(analysis.excluded$IT.Rating)
analysis.excluded$ME.Rating <- as.numeric(analysis.excluded$ME.Rating)
analysis.excluded$CP.Rating <- as.numeric(analysis.excluded$CP.Rating)


#Recode LIB condition into obvious variables based on presentation during Qualtrix Survey
recodeLIB2 <- c('Q3' = 'Favorable',
               'Q4' = 'Unfavorable')

analysis.excluded$LIB.Condition <- recodeLIB2[clean.excluded$LIB.Condition]

#Add composite column of mean from immigration policy, tax policy, and same-sex marriage policy. Porter et al. did not include the affirmative action policy in the original composite.

analysis.excluded$Policy.Composite <- apply(analysis.excluded[, c("LI.Rating",
                                                      "IT.Rating", 
                                                      "ME.Rating")],1,mean)

length(analysis.excluded$CP.Rating)
```


Replication main t-test not including 13 excluded participants.

```{r}
t.test(Policy.Composite ~ LIB.Condition, data = analysis.excluded)


cohen.d(analysis.excluded$Policy.Composite, analysis.excluded$LIB.Condition)
```
The confirmatory analysis replicates even when excluding 13 additional participants. Participants in the Favorable-LIB condition were more likely to rate the communicator as supporting Democratic leaning social policies than participants in the unfavorable condition, *t*(52) = 3.09, *p* = .003, *d* = 0.78. Therefore, I will continue to run exploratory analyses on the full dataset (78 participants)


#Continued Exploratory Analyses

###Affirmative Action Rating
```{r}
#Porter et al. conducted a t-test to see if the question about Affirmative Action followed the same trend as the other policy questions. 

AA.Trend = t.test(AA.Rating ~ LIB.Condition, data = analysis.final)

AA.Trend
```

While the means trend in the right direction (participants in the favorable group rated the communicator as being less likely to support repealing affirmative action), the t-test is not significant, which does not replicate the result of the original study (*t*(116) = 2.61, *p*=.01).


###Explicit Communicator Party Rating

As displayed in Figure 1.
```{r}
group_by(analysis.final, LIB.Condition) %>% 
  summarise(
    count = n(),
    mean = mean(CP.Rating, na.rm = TRUE),
    sd = sd(CP.Rating, na.rm = TRUE)
  )


CP.Trend = t.test(CP.Rating ~ LIB.Condition, data = analysis.final)

CP.Trend
```
The exploratory analysis for the explicit Communicator Rating does not replicate the original study. Although participants in the Favorable group had rated the communicator as more likely to be a Democrat (*M* = 5.22, *SD* = 1.51) than participants in the Unfavorable group (*M* = 4.88, *SD* = 1.60), this difference was not significant, *t*(75) = 0.97, *p* = 0.34. 
This is an interesting finding because it means that the implicit categorization (social policy ratings) had a signficant difference between groups, whereas the explicit categorization (communicator party) did not. I will explore the relationship between these categorizations below.
```{r}
#Exploratory graph of relationship between explicit and implicit ratings

ggplot(analysis.final, aes(x = CP.Rating, y = Policy.Composite)) +
  geom_point(aes(color = LIB.Condition), position = "jitter") +
  geom_smooth(method = "lm", se = FALSE) +
  labs(y = "Policy Composite Ratings",
       x = "Likelihood that the Communicator is a Democrat",
       color = "LIB Condition",    
       title = "Explicit and Implicit Ratings Comparison") + 
  scale_y_continuous(breaks = seq(0, 7, 1),
                     limits = c(0, 7)) +
  scale_x_continuous(breaks = seq(0, 7, 1),
                     limits = c(0,7)) +
  scale_color_brewer(palette = "Pastel1") +
  theme_classic()
  
```

The data seems to be concentrated on the higher end of the spectrum for both axes, indicating that participants in both groups were more likely to give higher ratings (indicating more likely to be a Democrat/support Democratic social policy issues) to the communicator.
Because the data seems to be concentrated on the higher end of the spectrum for both axes, I will conduct a correlation test to explore the relationship between the ratings.
```{r}
#Exploratory
cor.test(analysis.final$CP.Rating, analysis.final$Policy.Composite, method = "pearson")
```
The correlation test indicates ratings for the Communicator Party and Policy Composite are significantly correlated with a correlation coefficient of 0.35 and *p* = .002.

###Political Party Affiliation

```{r}
library(forcats)
analysis.final$politics <- politics_recode
summary(politics_recode)

policy.model <- lm(Policy.Composite ~ politics, data = analysis.final)
summary(policy.model)

party.model <- lm(CP.Rating ~ politics, data = analysis.final)
summary(party.model)
```
The linear model shows that self-reported political party affiliation does not moderate the Policy Composite ratings, *p* = .65.

## Discussion

### Summary of Replication Attempt

This attempt replicated the main confirmatory analysis of Study 2 from Porter et al. (2016), as there was a significant difference in Policy Composite ratings for the communicator based on the LIB Group Condition. This result stood even when 13 participants were excluded for failing an attention check. 

### Commentary

The exploratory analyses were less successful than the confirmatory analysis. One successful replication is that there was not a significant relationship between self-reported political party and either Policy Composite or Communicator Party ratings. Although the means trended in the correct direction for the Affirmative Action policy question, there was no signficant difference between the groups. The main finding from the original study is the explicit categorization of the communicator's political party, which did not replicate in my attempt. Exploring the interaction between explicit and implicit categorizations revealed a significant correlation between the two ratings, but visualizing the data does not clearly show why there would be a significant difference for the Policy Composite t-test and not the Communicator Party. One major difference between the original study and my replication that must be considered is political climate. The 2018 meanings of "Democrat" and "Republican" are arguably different than they were in 2016, which could provide some insight into why an implicit categorization replicated but an explicit did not.
